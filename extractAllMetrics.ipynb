{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9fadc83-e907-4c09-98fd-748a73865bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (5.10.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from nbformat) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from nbformat) (4.22.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.18.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.2.1)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\lelu4\\miniconda3\\envs\\mobvisenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (306)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The Parser module is used to convert the raw data to a standard format\n",
    "from mobvis.preprocessing.parser import Parser as par\n",
    "\n",
    "# The Locations module is used to find the Geo-locations of the trace, used by almost all metrics\n",
    "from mobvis.metrics.utils.Locations import Locations as loc\n",
    "# The HomeLocations module is used to find the Home-locations of the trace, used by some metrics\n",
    "from mobvis.metrics.utils.HomeLocations import HomeLocations as hloc\n",
    "# The Contacts module is used to detect the Contacts between the nodes, used by Social metrics\n",
    "from mobvis.metrics.utils.Contacts import Contacts as cnt\n",
    "\n",
    "# The MetricBuilder module can be used to instantiate all the metrics \n",
    "from mobvis.metrics.utils.MetricBuilder import MetricBuilder as mb\n",
    "\n",
    "# The metric and spatial plotters contains all the visualizations of MobVis\n",
    "from mobvis.plots.metric_plotter import *\n",
    "from mobvis.plots.spatial_plotter import *\n",
    "%pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f92ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" --- ADJUSTABLE PARAMETERS --- \"\"\"\n",
    "maxdistance = 15 # max distance to use when calculating the stay locations\n",
    "pause = 1 # time needed (in minutes) for a stay location to become a geo location\n",
    "disttype = \"euclidean\" # distance to use when calculating the contacts\n",
    "communicationRadius = 15 # radius to use when calculating the contacts\n",
    "traceToAnalyze = 5 # ID of the trace to analyze (script will analyze the ID given in traceNames)\n",
    "\n",
    "# True corresponds to reading the given file => use when you \"cached\" the data somewhere \n",
    "readFile = {\n",
    "    \"mainTrace\": True,\n",
    "    \"parsedTrace\": True,\n",
    "    \"stayAndGeoLoc\": True,\n",
    "    \"homeLoc\": True,\n",
    "    \"RADG\": True,\n",
    "    \"TRVD\": True,\n",
    "    \"VISO\": False,\n",
    "    \"TRVT\": True,\n",
    "    \"VIST\": True,\n",
    "    \"CONT\": True,\n",
    "    \"INCO\": True,\n",
    "    \"CONTACTS\": True\n",
    "}\n",
    "\n",
    "# True corresponds to generating and saving a given file => use when you want to cache the data \n",
    "# If you dont have the data cached yet, set the value to True in readFile and toSave\n",
    "# After you got the data, set the toSave value to False again and leave the readFile value as True\n",
    "toSave = {\n",
    "    \"parsedTrace\": True,\n",
    "    \"stayAndGeoLoc\": True,\n",
    "    \"homeLoc\": True,\n",
    "    \"RADG\": True,\n",
    "    \"TRVD\": True,\n",
    "    \"VISO\": False,\n",
    "    \"TRVT\": True,\n",
    "    \"VIST\": True,\n",
    "    \"CONT\": True,\n",
    "    \"INCO\": True,\n",
    "    \"CONTACTS\": True\n",
    "}\n",
    "\n",
    "\"\"\" --- END OF ADJUSTABLE PARAMETERS --- \"\"\"\n",
    "\n",
    "traceDetailsString = \"T\" + str(traceToAnalyze) + \"_dist\" + str(maxdistance) + \"_pause\" + str(pause)\n",
    "# e.g. T1_dist15_pause1\n",
    "traceRoot = \"./traces/\" # root directory, where all the traces are stored\n",
    "\n",
    "# Add the directory names of your trace here\n",
    "traceNames = {\n",
    "    1: \"trace1_09-06-2024_03.17.29.711\", \n",
    "    2: \"trace2_09-06-2024_03.17.41.719\", \n",
    "    3: \"trace3_09-06-2024_03.19.12.999\",\n",
    "    4: \"aSIOTmm_30-07-2024_18.39.23.577\", # 0.9\n",
    "    5: \"aSIOTmm_30-07-2024_18.44.34.013\" # 0.1\n",
    "    }\n",
    "# tracePath = traceRoot + traceNames[traceToAnalyze] + \"/pos_trace5DaysAddedZerosFixed.csv\"\n",
    "tracePath = traceRoot + traceNames[traceToAnalyze] + \"/pos_traceAddedZerosAndFixedAndLowsInterpolatedNaNRemoved.csv\"\n",
    "\n",
    "metricsPath = traceRoot + traceNames[traceToAnalyze] + \"/metrics/\"\n",
    "cachePath = traceRoot + traceNames[traceToAnalyze] + \"/cached/\"\n",
    "#\n",
    "# fileName = name + \"_dist_\" + str(maxdistance) + \"_pause_\" + str(pause)\n",
    "# if metricsPath and cachePath do not exist, create them\n",
    "# import os \n",
    "import os\n",
    "if not os.path.exists(metricsPath):\n",
    "    os.makedirs(metricsPath)\n",
    "if not os.path.exists(cachePath):\n",
    "    os.makedirs(cachePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26100f65-34f8-4a4b-95a7-c502f0f682a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trace = pd.read_csv(tracePath, names=['id', 'timestamp', 'x', 'y'], delimiter=',', skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901da8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# id, timestamp, x, y\n",
    "if toSave[\"parsedTrace\"]:\n",
    "    parsed_trace = par.parse(raw_trace=trace, is_ordered=True)\n",
    "    parsed_trace.to_csv(cachePath + \"parsedTrace_\" + traceDetailsString +  \".csv\", header=True, index=False)\n",
    "if readFile[\"parsedTrace\"]:\n",
    "    parsed_trace = pd.read_csv(cachePath + \"parsedTrace_\" + traceDetailsString + \".csv\", delimiter=',', names=['id', 'timestamp', 'x', 'y'], skiprows=1)\n",
    "# copyTrace = parsed_trace.copy() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20d64d",
   "metadata": {},
   "source": [
    "### Find Stay Locations and Geo Locations of the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed_trace = pd.read_csv(cachePath + \"parsedTrace_\" + traceDetailsString + \".csv\", delimiter=',', names=['id', 'timestamp', 'x', 'y'], skiprows=1)\n",
    "\n",
    "if toSave[\"stayAndGeoLoc\"]:\n",
    "    trace_loc, loc_centers = loc.find_locations(trace=parsed_trace, max_d=maxdistance, pause_threshold=pause, dist_type=disttype)\n",
    "    trace_loc.to_csv(cachePath + \"trace_loc_\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "    loc_centers.to_csv(cachePath + \"loc_centers_\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "if readFile[\"stayAndGeoLoc\"]:\n",
    "    trace_loc = pd.read_csv(cachePath + \"trace_loc_\" + traceDetailsString + \".csv\", delimiter=',', names=['id', 'x', 'y', 'sl', 'gl', 'index', 'timestamp'], skiprows=1)\n",
    "    loc_centers = pd.read_csv(cachePath + \"loc_centers_\" + traceDetailsString + \".csv\", delimiter=',', names=['id', 'sl', 'x', 'y', 'max_x', 'min_x', 'max_y', 'min_y'], skiprows=1)\n",
    "\n",
    "trace_loc = trace_loc.astype({\"id\": int, \"x\": float, \"y\": float, \"sl\": int, \"gl\": bool, \"index\": float, \"timestamp\": float})\n",
    "loc_centers = loc_centers.astype({\"id\": int, \"sl\": int, \"x\": float, \"y\": float, \"max_x\": float, \"min_x\": float, \"max_y\": float, \"min_y\": float})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541f3c9",
   "metadata": {},
   "source": [
    "### Home locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650130a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if toSave[\"homeLoc\"]:\n",
    "    trace_homes = hloc.find_homes(trace_loc=trace_loc)\n",
    "    trace_homes.to_csv(cachePath + \"trace_homes\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "if readFile[\"homeLoc\"]:\n",
    "    trace_homes = pd.read_csv(cachePath + \"trace_homes\" + traceDetailsString + \".csv\", delimiter=',', names=['id', 'home_location', 'x', 'y'], skiprows=1)\n",
    "\n",
    "# trace_homes.head()\n",
    "trace_homes = trace_homes.astype({\"id\": int, \"home_location\": int, \"x\": float, \"y\": float})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa1446",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155f938",
   "metadata": {},
   "source": [
    "## Spatial Metrics (RADG, TravelDistance, VisitOrder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ded3c",
   "metadata": {},
   "source": [
    "##### Note: VisitOrder takes a hell lot of time and doesn't really provide much of an insight. You probably want to extract this metric last."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb88940",
   "metadata": {},
   "source": [
    "When calculating RADG you need the home locations as an input. When you extract them with MobVis though, they tend to be incorrect. Therefore use the ground truth data from the mobility model as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real ground truth home locations given by the mobility model\n",
    "realHomes = pd.read_csv(traceRoot + traceNames[traceToAnalyze] + \"/home_locationsFixed.csv\", delimiter=',', names=['id', 'x', 'y'], skiprows=1)\n",
    "\n",
    "# join realHomes with trace_homes on id\n",
    "merged = pd.merge(trace_homes, realHomes, on='id', how='inner', suffixes=('_trace', ''))\n",
    "merged.head()\n",
    "\n",
    "\n",
    "if toSave[\"RADG\"]:\n",
    "    trace_radg = mb.build_metric('RADG', trace=parsed_trace, trace_loc=trace_loc, sl_centers=loc_centers, homes=merged, dist_type=\"Euclidean\").extract()\n",
    "    trace_radg.to_csv(metricsPath + \"RADGRealHomes\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "if readFile[\"RADG\"]:\n",
    "    trace_radg = pd.read_csv(metricsPath + \"RADGRealHomes\" + traceDetailsString + \".csv\", delimiter=',', names = [\"id\",\"home_location\",\"radius_of_gyration\"], skiprows=1)\n",
    "\n",
    "trace_radg = trace_radg.astype({\"id\": int, \"home_location\": int, \"radius_of_gyration\": float})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3127e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if toSave[\"TRVD\"]:\n",
    "    trace_trvd = mb.build_metric('TRVD', trace_loc=trace_loc, dist_type=\"Euclidean\").extract()\n",
    "    trace_trvd.to_csv(metricsPath + \"TRVD\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "if readFile[\"TRVD\"]:\n",
    "    trace_trvd = pd.read_csv(metricsPath + \"TRVD\" + traceDetailsString + \".csv\", delimiter=',', names = [\"id\",\"travel_distance\",\"init_sl\",\"final_sl\",\"ix\",\"iy\",\"fx\",\"fy\"], skiprows=1)\n",
    "\n",
    "trace_trvd = trace_trvd.astype({\"id\": int, \"travel_distance\": float, \"init_sl\": int, \"final_sl\": int, \"ix\": float, \"iy\": float, \"fx\": float, \"fy\": float})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275d915",
   "metadata": {},
   "source": [
    "VisitOrder has some flaws, therefore you need to do it in this complicated way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ad82555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if toSave[\"VISO\"]:\n",
    "# # Calculate Stay and Geo locations again, because VISO only works if GL's have been calculated by loc.geo_locations lmao\n",
    "# # Reset index of geos because VISO metric cant extract it otherwise lmao\n",
    "#     sl = loc.stay_locations_euclidean(parsed_trace, maxdistance)\n",
    "#     geos = loc.geo_locations(sl, pause)\n",
    "#     geos1 = geos.loc[geos.gl == True]\n",
    "#     geos1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "#     trace_viso = mb.build_metric('VISO', trace_loc=geos1).extract()\n",
    "#     trace_viso.to_csv(metricsPath + \"VISO\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "# if readFile[\"VISO\"]:\n",
    "#     trace_viso = pd.read_csv(metricsPath + \"VISO\" + traceDetailsString + \".csv\", delimiter=',', names=[\"id\",\"timestamp\",\"x\",\"y\",\"sl\",\"visit_order\"], skiprows=1)\n",
    "\n",
    "# trace_viso = trace_viso.astype({\"id\": int, \"timestamp\": float, \"x\": float, \"y\": float, \"sl\": int, \"visit_order\": int})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c80723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # geos1 = geos[geos['gl'] == True]\n",
    "# geos1 = geos.loc[geos.gl == True]\n",
    "# geos1.reset_index(drop=True, inplace=True)\n",
    "# # print(int(geos1.id[0]))\n",
    "# print(geos1.id)\n",
    "# if toSave[\"VISO\"]:\n",
    "#     trace_viso = mb.build_metric('VISO', trace_loc=geos1).extract()\n",
    "#     trace_viso.to_csv(metricsPath + \"VISO\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "# if readFile[\"VISO\"]:\n",
    "#     trace_viso = pd.read_csv(metricsPath + \"VISO\" + traceDetailsString + \".csv\", delimiter=',', skiprows=1)\n",
    "# # # # # Add NAMES \n",
    "\n",
    "# if saveData:\n",
    "#     trace_contacts = cnt.detect_contacts(df=parsed_trace, radius=0.13, dist_type=\"euclidean\")\n",
    "#     trace_contacts.to_csv(fileName + \".trace_contacts.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919179",
   "metadata": {},
   "source": [
    "## Temporal Metrics (TravelTime, VisitTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919959b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if toSave[\"TRVT\"]:\n",
    "    trace_trvt = mb.build_metric('TRVT', trace_loc=trace_loc).extract()\n",
    "    trace_trvt.to_csv(metricsPath + \"TRVT\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "if readFile[\"TRVT\"]:\n",
    "    trace_trvt = pd.read_csv(metricsPath + \"TRVT\" + traceDetailsString + \".csv\", delimiter=',', names=[\"id\",\"init_sl\",\"final_sl\",\"t_exit\",\"t_arrival\",\"travel_time\"], skiprows=1)\n",
    "\n",
    "trace_trvt = trace_trvt.astype({\"id\": int, \"init_sl\": int, \"final_sl\": int, \"t_exit\": float, \"t_arrival\": float, \"travel_time\": float})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b08482",
   "metadata": {},
   "outputs": [],
   "source": [
    "if toSave[\"VIST\"]:\n",
    "    trace_vist = mb.build_metric('VIST', trace_loc=trace_loc).extract()\n",
    "    trace_vist.to_csv(metricsPath + \"VIST\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "if readFile[\"VIST\"]:\n",
    "    trace_vist = pd.read_csv(metricsPath + \"VIST\" + traceDetailsString + \".csv\", delimiter=',', names=[\"id\", \"timestamp\", \"sl\", \"visit_time\"], skiprows=1)\n",
    "\n",
    "trace_vist = trace_vist.astype({\"id\": int, \"timestamp\": float, \"sl\": int, \"visit_time\": float})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a30ae",
   "metadata": {},
   "source": [
    "## Social Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication range = 50m radius\n",
    "if toSave[\"CONT\"]:\n",
    "    trace_contacts = cnt.detect_contacts(df=parsed_trace, radius=communicationRadius, dist_type=disttype)\n",
    "    trace_contacts.to_csv(metricsPath + \"CONT_\" + str(communicationRadius) + \"_\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "if readFile[\"CONT\"]:\n",
    "    trace_contacts = pd.read_csv(metricsPath + \"CONT_\" + str(communicationRadius) + \"_\" + traceDetailsString + \".csv\", delimiter=',', names=[\"id1\", \"id2\", \"x1\", \"y1\", \"x2\", \"y2\", \"timestamp\"], skiprows=1)\n",
    "\n",
    "trace_contacts = trace_contacts.astype({\"id1\": int, \"id2\": int, \"x1\": float, \"y1\": float, \"x2\": float, \"y2\": float, \"timestamp\": float})\n",
    "\n",
    "type(trace_contacts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19196e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if toSave[\"INCO\"]:\n",
    "    trace_inco = mb.build_metric('INCO', contacts_df=trace_contacts).extract()\n",
    "    trace_inco.to_csv(metricsPath + \"INCO\" + traceDetailsString + \".csv\", header=True, index=False)\n",
    "if readFile[\"INCO\"]:\n",
    "    trace_inco = pd.read_csv(metricsPath + \"INCO\" + traceDetailsString + \".csv\", delimiter=',', names=[\"id1\", \"id2\", \"intercontact_time\"], skiprows=1)\n",
    "\n",
    "trace_inco = trace_inco.astype({\"id1\": int, \"id2\": int, \"intercontact_time\": float})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
