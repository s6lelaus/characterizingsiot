{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9fadc83-e907-4c09-98fd-748a73865bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The Parser module is used to convert the raw data to a standard format\n",
    "from mobvis.preprocessing.parser import Parser as par\n",
    "\n",
    "# The Locations module is used to find the Geo-locations of the trace, used by almost all metrics\n",
    "from mobvis.metrics.utils.Locations import Locations as loc\n",
    "# The HomeLocations module is used to find the Home-locations of the trace, used by some metrics\n",
    "from mobvis.metrics.utils.HomeLocations import HomeLocations as hloc\n",
    "# The Contacts module is used to detect the Contacts between the nodes, used by Social metrics\n",
    "from mobvis.metrics.utils.Contacts import Contacts as cnt\n",
    "\n",
    "# The MetricBuilder module can be used to instantiate all the metrics \n",
    "from mobvis.metrics.utils.MetricBuilder import MetricBuilder as mb\n",
    "\n",
    "# The metric and spatial plotters contains all the visualizations of MobVis\n",
    "from mobvis.plots.metric_plotter import *\n",
    "from mobvis.plots.spatial_plotter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb847b6",
   "metadata": {},
   "source": [
    "Script to \"fix\"/standardize the trace.\n",
    "Given a generated trace with human nodes, get a trace without human nodes and initialize any devices that haven't moved in the whole trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd565403",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "def fixInfoCSV(filename):\n",
    "    \"\"\"\n",
    "    Transforms the first dataset by removing 'HumanNode' entries, adjusting IDs to start from 0,\n",
    "    and mapping old owner IDs to new ones incrementing by 1 for each new owner\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame\n",
    "    df = pd.read_csv(filename, names=['id', 'owner', 'type'], sep=\",\", skiprows=1)\n",
    "\n",
    "    # Standardize the type column by stripping whitespace and converting to lowercase\n",
    "    df['type'] = df['type'].str.strip().str.lower()\n",
    "\n",
    "    # Filter out 'humannode' types\n",
    "    df = df[df['type'] != 'humannode']\n",
    "\n",
    "    # Add an extra column for the old id\n",
    "    df['old_id'] = df['id']\n",
    "\n",
    "    # Adjust ids to start from 0\n",
    "    df['id'] = range(len(df))\n",
    "\n",
    "    # Map old owner IDs to new ones incrementing by 1 for each new owner\n",
    "    unique_owners = {}\n",
    "    current_owner_id = 1\n",
    "\n",
    "    def get_new_owner_id(old_owner_id):\n",
    "        nonlocal current_owner_id\n",
    "        if old_owner_id not in unique_owners:\n",
    "            unique_owners[old_owner_id] = current_owner_id\n",
    "            current_owner_id += 1\n",
    "        return unique_owners[old_owner_id]\n",
    "\n",
    "    df['owner'] = df['owner'].apply(get_new_owner_id)\n",
    "\n",
    "    return df\n",
    "\n",
    "def fixPosTraceCSV(filename, id_mapping):\n",
    "    \"\"\"\n",
    "    Replaces the old IDs in pos_trace with the new ones\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame\n",
    "    df = pd.read_csv(filename, names=['id', 'x', 'y', 'time'], sep=\",\", skiprows=1)\n",
    "\n",
    "    # Replace old IDs with new IDs using the mapping\n",
    "    df['id'] = df['id'].map(id_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "def fixHomeLocationsCSV(filename, id_mapping):\n",
    "    # Convert to DataFrame\n",
    "    df = pd.read_csv(filename, names=['id', 'x', 'y'], sep=\",\", skiprows=1)\n",
    "\n",
    "    # Replace old IDs with new IDs using the mapping\n",
    "    df['id'] = df['id'].map(id_mapping)\n",
    "    df = df.dropna(subset=['id'])\n",
    "    # convert id to int\n",
    "    df['id'] = df['id'].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def generateInitTimestamps(fixedHomeLocationFilename):\n",
    "    '''\n",
    "    Extend the home location dataframe (id, x, y) to include a timestamp column with value 0\n",
    "    Can be appended manually to the trace file\n",
    "    '''\n",
    "    # Convert to DataFrame\n",
    "    df = pd.read_csv(fixedHomeLocationFilename, names=['id', 'x', 'y'], sep=\",\", skiprows=1)\n",
    "    # Add a timestamp column with value 0\n",
    "    df['timestamp'] = 0.0\n",
    "    return df\n",
    "\n",
    "def getHumanNodes():\n",
    "    '''\n",
    "    Returns the IDs of the human nodes\n",
    "    '''\n",
    "    df = pd.read_csv(\"info.csv\", names=['id', 'owner', 'type'], sep=\",\", skiprows=1)\n",
    "    return df[df['type'] == ' HumanNode']['id'] # yes the space is intentional\n",
    "\n",
    "def removeHumanNodesFromPosTrace(humanNodes:list, posTraceFilename):\n",
    "    '''\n",
    "    Removes the human nodes from the pos_trace file\n",
    "    '''\n",
    "    # Convert to DataFrame\n",
    "    df = pd.read_csv(posTraceFilename, names=['id', 'x', 'y', 'time'], sep=\",\", skiprows=1)\n",
    "    # Remove the human nodes\n",
    "    df = df[~df['id'].isin(humanNodes)]\n",
    "    return df\n",
    "\n",
    "def removeHumanNodesFromHomeLocation(humanNodes:list, homelocationFilename):\n",
    "    '''\n",
    "    Removes the human nodes from the pos_trace file\n",
    "    '''\n",
    "    # Convert to DataFrame\n",
    "    df = pd.read_csv(homelocationFilename, names=['id', 'x', 'y'], sep=\",\", skiprows=1)\n",
    "    # Remove the human nodes\n",
    "    df = df[~df['id'].isin(humanNodes)]\n",
    "    return df\n",
    "\n",
    "# Add a lot of redundant data/files, in case of errors\n",
    "\n",
    "originalPosTrace = pd.read_csv(\"pos_trace.csv\", names=['id', 'x', 'y', 'time'], sep=\",\", skiprows=1)\n",
    "originalPosTrace.to_csv(\"pos_traceOriginal.csv\", index=False, header=True)\n",
    "\n",
    "# Remove Human Nodes from the trace \n",
    "removedHumanNodes = removeHumanNodesFromPosTrace(getHumanNodes(), \"pos_trace.csv\")\n",
    "# Overwrite pos_trace with the one where no Human Nodes are present\n",
    "removedHumanNodes.to_csv(\"pos_trace.csv\", index=False, header=True)\n",
    "\n",
    "# Transform the first dataset\n",
    "infoCSV = fixInfoCSV(\"info.csv\")\n",
    "# Save transformed infocsv\n",
    "infoCSV.to_csv(\"infoFixed.csv\", index=False, header=True)\n",
    "\n",
    "# Create a dictionary to map old IDs to new IDs\n",
    "id_mapping = dict(zip(infoCSV['old_id'], infoCSV['id']))\n",
    "\n",
    "# Replace the old IDs in the second dataset with the new IDs\n",
    "posTraceCSV = fixPosTraceCSV(\"pos_trace.csv\", id_mapping)\n",
    "posTraceCSV.to_csv(\"pos_traceFixed.csv\", index=False, header=True)\n",
    "\n",
    "\n",
    "\n",
    "# # Remove humanNodes from home_locations.csv\n",
    "fixedHomesCSV = fixHomeLocationsCSV(\"home_locations.csv\", id_mapping)\n",
    "fixedHomesCSV.to_csv(\"home_locationsFixed.csv\", index=False, header=True)\n",
    "\n",
    "\n",
    "# Initialize/Add devices: Homelocation to be their (x,y) for timestep 0\n",
    "initTimeStamps = generateInitTimestamps(\"home_locationsFixed.csv\")\n",
    "initTimeStamps.to_csv(\"init_timestamps.csv\", index=False, header=True)\n",
    "\n",
    "# Parse the trace once\n",
    "parsed_trace = par.parse(posTraceCSV, is_ordered=False)\n",
    "parsed_trace.to_csv('pos_traceParsed.csv', index=False, header=True)\n",
    "parsed_trace = pd.read_csv('pos_traceParsed.csv')\n",
    "\n",
    "# # Crop the trace here to only include the rows that have a timestamp < x and slightly adjust the code\n",
    "# x = 86400*8 # x days\n",
    "# croppedTrace = parsed_trace[parsed_trace['timestamp'] < x]\n",
    "# croppedTrace.to_csv('pos_traceFixed5Days.csv', index=False, header=True)\n",
    "\n",
    "# print the ids that have no rows in posTraceCSV\n",
    "maxID = posTraceCSV['id'].max()\n",
    "traceZeros = posTraceCSV.groupby(['id']).size().reindex(range(0, maxID), fill_value=0)\n",
    "zeroRows = traceZeros[traceZeros == 0]\n",
    "# for i in zeroRows.index:\n",
    "#     print(i)\n",
    "zeroRowsDF = pd.DataFrame(zeroRows.index, columns=['id'])\n",
    "zeroRowsDF.to_csv(\"idsWithZeroRows.txt\", index=False, header=True)\n",
    "\n",
    "# # Get ids from the croppedTrace that have zero rows\n",
    "# croppedTraceZeros = croppedTrace.groupby(['id']).size().reindex(range(0, 534), fill_value=0)\n",
    "# zeroRows = croppedTraceZeros[croppedTraceZeros == 0]\n",
    "\n",
    "# Get ids with from idsWithZeroRows.txt\n",
    "idsWithZeroRows = pd.read_csv(\"idsWithZeroRows.txt\", names=['id'], sep=\",\", skiprows=1)\n",
    "idsWithZeroRows['id'] = idsWithZeroRows['id'].astype(int)\n",
    "\n",
    "# Get initTimeStamps for ids in idsWithZeroRows\n",
    "initTimeStampsZeroRows = initTimeStamps[initTimeStamps['id'].isin(idsWithZeroRows['id'])]\n",
    "initTimeStampsZeroRows.to_csv(\"init_timestampsZeroRows.csv\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids from the croppedTrace that have zero rows\n",
    "# croppedTraceZeros = croppedTrace.groupby(['id']).size().reindex(range(0, 534), fill_value=0)\n",
    "# zeroRows = croppedTraceZeros[croppedTraceZeros == 0]\n",
    "# print(zeroRows)\n",
    "\n",
    "# for every id in zeroRows, get the corresponding init location from initTimeStamps\n",
    "initTimeStampsZeroRows = initTimeStamps[initTimeStamps['id'].isin(zeroRows.index)]\n",
    "print(initTimeStampsZeroRows)\n",
    "\n",
    "# Append initTimeStampsZeroRows to trace\n",
    "concat = pd.concat([parsed_trace, initTimeStampsZeroRows])\n",
    "\n",
    "# Parse the trace to MobVis' format and save it\n",
    "final = par.parse(concat, is_ordered=False)\n",
    "final.to_csv('pos_traceAddedZerosAndFixed.csv', index=False, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
